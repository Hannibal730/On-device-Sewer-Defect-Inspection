논문 제목: Low Cost Sewer Defect Diagnosis Transformer for On-Device Processing
저자 및 소속

(작성자 정보)
초록 (Abstract)
[배경] 도시 인프라 노후화와 하수관 점검의 중요성.
[문제점] 기존 딥러닝 시스템의 고성능 서버 의존성 및 엣지 디바이스에서의 실시간 처리 한계.
[제안 모델] 엣지 디바이스에 최적화된 새로운 경량 하이브리드 아키텍처, LCD-Transformer 제안.
[핵심 구조] 경량 CNN 기반 패치 인코더와 경량 트랜스포머 디코더의 결합.
[핵심 기여: 어텐션 풀링] 소수의 학습 가능한 '잠재 쿼리'를 사용하여, 입력 이미지의 특징에 적응적인 '동적 쿼리'를 생성하는 어텐션 풀링(Attention Pooling) 메커니즘 추가.
[실험 결과 요약] Sewer-ML 데이터셋에서 기존 경량 모델 대비 파라미터 및 연산량(FLOPs)의 현저한 감소와 함께 동등 이상의 탐지 성능 달성.
[결론 및 영향] 제안 모델의 실용성 강조: 하수관 점검 로봇 등 자원이 제한된 환경에 적용 가능한 실시간, 저전력 솔루션으로서의 가능성 제시.
1. 서론 (Introduction)
1.1. 문제의 중요성 및 배경
하수관 노후화의 심각성 및 사회/환경적 영향.
CCTV를 활용한 주기적 점검의 필요성.
1.2. 기존 접근법의 한계
수동 분석: 전문가 육안 판독의 문제점 (비용, 시간, 주관성).
기존 자동화 연구: 고성능 CNN 모델(ResNet 등) 기반 연구들의 성과와 온디바이스 처리의 장벽 지적.
1.3. 제안하는 솔루션: LCD-Transformer
본 논문에서 제안하는 경량 하이브리드 아키텍처 "LCD-Transformer" 소개.
CNN의 효율적인 지역 특징 추출 능력과 트랜스포머의 전역적 문맥 이해 능력을 결합.
1.4. 핵심 기여 (Key Contributions)
Contribution 1: 경량 하이브리드 아키텍처 설계
이미지를 패치로 분할하고, 모든 패치가 공유된(shared) 경량 CNN 백본을 통과하는 구조를 통해 파라미터 효율성 극대화.
Contribution 2: 어텐션 풀링을 통한 동적 쿼리 생성
고정된 쿼리 대신, 소수의 학습 가능한 잠재 쿼리를 사용하여 입력 이미지의 특징들로부터 동적으로 쿼리를 생성하는 어텐션 풀링 메커니즘 제안.
Contribution 3: 포괄적인 온디바이스 효율성 검증
분류 성능 뿐만 아니라, 파라미터 수, 연산량(FLOPs), 추론 시간, 메모리 사용량을 종합적으로 비교 분석.
1.5. 논문 구성
2장부터 5장까지의 내용을 간략히 안내.
2. 관련 연구 (Related Work)
2.1. 하수관 결함 탐지를 위한 컴퓨터 비전
2.2. 경량 CNN 모델 (Lightweight CNNs)
2.3. 비전 트랜스포머 (Vision Transformers, ViT)
2.4. 하이브리드 CNN-Transformer 모델
3. 제안하는 방법 (Proposed Method)
3.1. 전체 아키텍처 개요

제안하는 LCD-Transformer는 입력 이미지 $I$를 받아 최종 로짓(Logits)을 출력하는 함수 $f_{LCD}$로 정의할 수 있다. $$ \text{Logits} = f_{LCD}(I; \theta) = (\Phi_{cls} \circ \Phi_{dec} \circ \Phi_{enc})(I) $$ 여기서 $\Phi_{enc}$, $\Phi_{dec}$, $\Phi_{cls}$는 각각 패치 인코더, 디코더, 분류기를 나타내며, $\theta$는 모델의 모든 학습 가능한 파라미터이다.
3.2. 패치 컨볼루션 인코더 (Patch Convolutional Encoder)

인코더 $\Phi_{enc}$는 2D 이미지를 1D 특징 시퀀스로 변환한다.
1. 입력 및 패치 분할: 입력 이미지 $I \in \mathbb{R}^{H \times W \times C}$는 겹치지 않는 $N_p$개의 패치 ${p_1, p_2, ..., p_{N_p}}$로 분할된다. 각 패치 $p_i \in \mathbb{R}^{S \times S \times C}$이며, 여기서 $S$는 패치 크기(patch_size)이고 $N_p = (H/S) \times (W/S)$이다.
2. 공유 CNN 특징 추출: 모든 패치 $p_i$는 가중치를 공유하는 CNN 특징 추출기 $\Phi_{cnn}$을 통과한다. $\Phi_{cnn}$은 config.yaml의 cnn_feature_extractor에 명시된 경량 CNN(EfficientNet-B0 등)의 초기 레이어들과 채널 차원을 맞추기 위한 1x1 컨볼루션으로 구성된다. 이후 AdaptiveAvgPool을 통해 각 패치는 $D_{feat}$ 차원의 특징 벡터 $\mathbf{f}i$로 변환된다. $$ \mathbf{f}i = \text{Flatten}(\text{AdaptiveAvgPool}(\Phi{cnn}(p_i))) \in \mathbb{R}^{D{feat}} $$
3. 최종 인코더 출력: 모든 패치 특징 벡터들을 연결하고 LayerNorm을 적용하여 최종 인코더 출력 시퀀스 $X_{enc} \in \mathbb{R}^{N_p \times D_{feat}}$를 생성한다. $$ X_{enc} = \text{LayerNorm}([\mathbf{f}_1; \mathbf{f}2; ...; \mathbf{f}{N_p}]) $$
3.3. 경량 크로스-어텐션 디코더 (Lightweight Cross-Attention Decoder)

디코더 $\Phi_{dec}$는 인코더가 생성한 패치 특징 시퀀스 $X_{enc}$를 보고 분류에 필요한 핵심 정보를 요약한다.
3.3.1. 디코더 입력 준비 (Input Preparation)
디코더의 입력인 키(Key)와 값(Value)은 인코더 출력 시퀀스 $X_{enc}$에 선형 변환 $W_{emb}$와 학습 가능한 위치 인코딩 $PE \in \mathbb{R}^{N_p \times D_{emb}}$를 적용하여 생성된다. (models.py: W_feat2emb, PE) $$ K = V = W_{emb}(X_{enc}) + PE \in \mathbb{R}^{N_p \times D_{emb}} $$
3.3.2. 어텐션 풀링을 통한 동적 쿼리 생성 (Dynamic Query Generation via Attention Pooling)
본 논문의 핵심 아이디어로, config.yaml의 attn_pooling: true에 해당한다.
1. 잠재 쿼리 준비: 모델은 $N_q$개의 학습 가능한 잠재 쿼리 $Q_{latent} \in \mathbb{R}^{N_q \times D_{feat}}$를 갖는다. 이 쿼리는 선형 변환을 거쳐 임베딩 차원으로 변환된다. (models.py: learnable_queries) $$ Q'{latent} = W{emb}(Q_{latent}) \in \mathbb{R}^{N_q \times D_{emb}} $$
2. 어텐션 스코어 계산: 잠재 쿼리 $Q'{latent}$와 인코더 출력의 Key 시퀀스 $K$ 간의 어텐션 스코어를 계산한다. $$ \text{Scores} = \text{softmax}\left(\frac{Q'{latent} K^T}{\sqrt{d_k}}\right) \in \mathbb{R}^{N_q \times N_p} $$
3. 동적 쿼리 생성: 계산된 스코어를 Value 시퀀스 $V$와 가중합하여 최종 동적 쿼리 $Q_{dynamic}$를 생성한다. 이 쿼리는 첫 번째 디코더 레이어의 입력으로 사용된다. $$ Q_{dynamic} = \text{Scores} \cdot V \in \mathbb{R}^{N_q \times D_{emb}} $$
3.3.3. 디코더 레이어 (Decoder Layer)
$L$개의 디코더 레이어는 Multi-Head Cross-Attention (MHCA)과 Feed-Forward Network (FFN)로 구성된다. $l$-번째 레이어의 입력 쿼리를 $Q^{(l-1)}$이라 할 때, 출력 $Q^{(l)}$은 다음과 같이 계산된다. $$ \hat{Q}^{(l)} = \text{LayerNorm}(Q^{(l-1)} + \text{MHCA}(Q^{(l-1)}, K, V)) $$ $$ Q^{(l)} = \text{LayerNorm}(\hat{Q}^{(l)} + \text{FFN}(\hat{Q}^{(l)})) $$
여기서 MHCA는 다음과 같이 정의된다. $$ \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V $$
FFN은 두 개의 선형 레이어와 GEGLU 활성화 함수로 구성된다. $$ \text{FFN}(x) = W_2(\text{GEGLU}(W_1(x))) $$
3.4. 분류기 (Classifier)

분류기 $\Phi_{cls}$는 최종 디코더 레이어의 출력 $Z = Q^{(L)} \in \mathbb{R}^{N_q \times D_{emb}}$를 입력받는다.
먼저 Projection4Classifier $\Phi_{proj}$를 통해 차원이 변환되고 Flatten된다. $$ \text{Features} = \text{Flatten}(\Phi_{proj}(Z)) \in \mathbb{R}^{N_q \times D_{feat}} $$
이후 간단한 MLP 분류기를 통과하여 최종 클래스 로짓을 출력한다. $$ \text{Logits} = \text{MLP}(\text{Features}) \in \mathbb{R}^{N_{cls}} $$
4. 실험 (Experiments)
4.1. 데이터셋 (Datasets)
Sewer-ML: 사용한 공개 데이터셋의 특징, 클래스 구성('Normal', 'Defect') 설명.
데이터 분할: dataloader.py에 따라 훈련/검증/테스트 세트로 분할한 방식 설명.
4.2. 실험 환경 및 구현 세부사항
하이퍼파라미터 표: config.yaml의 주요 설정값을 표로 정리.
데이터 전처리: dataloader.py의 train_transform과 valid_test_transform에 적용된 데이터 증강 및 정규화 기법 상세 기술.
손실 함수 (Loss Function): 모델은 표준 교차 엔트로피(Cross-Entropy) 손실 함수 $\mathcal{L}{CE}$를 최소화하도록 훈련된다. $$ \mathcal{L}{CE} = -\sum_{i=1}^{N_{cls}} y_i \log(\hat{y}_i) $$ 여기서 $y_i$는 실제 레이블, $\hat{y}_i$는 모델의 예측 확률이다.
4.3. 평가 지표 (Evaluation Metrics)
분류 성능: Accuracy, Precision, Recall, F1-Score. 각 지표의 수식을 명시한다. $$ \text{Precision} = \frac{TP}{TP+FP}, \quad \text{Recall} = \frac{TP}{TP+FN} $$ $$ \text{F1-Score} = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}} $$
온디바이스 효율성: 4가지 핵심 지표 (파라미터 수, GFLOPs, 추론 시간, 메모리 사용량).
4.4. 실험 결과 및 분석
4.4.1. 베이스라인 모델과의 성능 비교
baseline.py에서 사용된 모델(ResNet-18, MobileNet-V2 등) 소개.
결과 표: 모든 모델에 대해 4.3에서 정의한 모든 평가 지표를 비교하는 종합 표 제시.
분석: 제안 모델이 훨씬 적은 파라미터와 연산량으로 베이스라인과 동등하거나 더 나은 F1-Score를 달성했음을 수치적으로 강조.
4.4.2. 어블레이션 스터디 (Ablation Study)
어텐션 풀링의 효과: attn_pooling을 false로 설정하고 고정 쿼리를 사용했을 때와 성능/파라미터 비교.
CNN 백본의 영향: cnn_feature_extractor를 다른 종류로 변경했을 때의 성능 변화 비교.
디코더 깊이의 영향: num_decoder_layers를 변경하며 성능과 효율성 트레이드오프 분석.
4.4.3. 정성적 분석: 어텐션 시각화 (Qualitative Analysis)
plot.py로 생성된 어텐션 맵 이미지 제시.
모델이 결함 이미지의 실제 결함 영역에 높은 어텐션 가중치를 부여하는 사례를 보여줌.
5. 결론 (Conclusion)
연구 요약: 제안한 LCD-Transformer의 핵심 아이디어(경량 하이브리드 구조, 어텐션 풀링) 요약.
성과 강조: 실험을 통해 입증된 제안 모델의 높은 효율성과 경쟁력 있는 성능 강조.
시사점 및 기대효과: 온디바이스 AI 분야에 기여할 수 있는 실용적 가치 설명.
향후 연구 방향 (Future Work):
다중 결함 분류(Multi-label classification) 문제로의 확장.
결함 영역 분할(Segmentation) 태스크로의 발전 가능성 제시.
참고문헌 (References)
(인용한 모든 논문, 데이터셋, 소프트웨어 라이브러리 목록)
