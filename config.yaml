# =============================================================================
# 1. 실행 및 데이터 관련 설정 (run.py, baseline.py 공용)
# =============================================================================
run:
  mode: 'train' # 실행 모드. 'train': 모델 훈련, 'inference': 모델 추론 및 성능 평가
  cuda: true # true: CUDA 사용 시도. false: CPU만 사용. CUDA를 사용할 수 없는 경우 자동으로 CPU로 전환됩니다.
  only_inference: false # true: 정답 레이블 없이 순수 추론만 수행. false: 정답 레이블과 비교하여 성능 평가.
  only_inference_dir: 'log/Sewer-ML/run_20251108_124343'   # 추론 모드에서 사용할 훈련된 모델이 포함된 디렉토리의 경로
  global_seed: 42 # 프로그램 전체의 재현성을 위한 전역 랜덤 시드. None으로 설정 시 비활성화.
  model_path: 'best_model.pth' # 훈련 시 저장할 최고 성능 모델의 파일 이름 또는 추론 시 불러올 모델의 파일 이름. 
  show_log: true # true: 로그를 콘솔에 출력하고 파일로 저장. false: 모든 로깅 비활성화.
  
  # --- 데이터셋 설정 ---
  dataset:
    name: 'Sewer-ML' # 사용할 데이터셋 이름 (로깅 및 폴더명 생성에 사용) Sewer-TAPNEW, Sewer-TAP, Sewer-ML
    type: 'csv' # type: 'csv' (이미지 폴더 + CSV 라벨) 또는 'image_folder' (클래스별 폴더 구조)
    train_split_ratio: 0.8 # 'image_folder' 타입일 때 사용할 훈련 데이터 비율 (나머지는 테스트/검증 데이터가 됨)

    # 데이터셋 경로 설정
    paths:
      # 1. 'csv' 타입 데이터셋 경로
      train_img_dir: '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/train'
      valid_img_dir: '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid'
      test_img_dir: '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/valid'
      train_csv: '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Train.csv'
      valid_csv: '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv'
      test_csv: '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-ML/SewerML_Val.csv'

      # 2. 'image_folder' 타입 데이터셋 경로
      # /home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAP
      # /home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW
      img_folder: '/home/cau/workspace/data/Sewer/Sewer-TAPNEW'
      # img_folder: '/home/user/workspace/disk/nvme1/data/Sewer/Sewer-TAPNEW'

  # 각 데이터셋에서 무작위로 샘플링할 데이터 비율. 1.0이면 전체 데이터 사용.
  random_sampling_ratio:
    train: 1.0
    valid: 1.0
    test: 1.0
  num_workers: 16 # 데이터 로딩 시 사용할 CPU 프로세스 수. 0이면 메인 프로세스만 사용. (~24)

# =============================================================================
# 2. 훈련 하이퍼파라미터 (run.py 전용)
# =============================================================================
training_run:
  epochs: 90                    # Sewer-ML이 90에포크 사용하여서 동일한 90으로 설정
  batch_size: 256                # 훈련 및 평가 시 사용할 배치 크기. GPU 메모리에 따라 조절합니다.
  pre_trained: false             # true: ImageNet 사전 훈련 가중치 사용, false: 무작위 초기화 가중치 사용
  optimizer: 'adamw'            # 사용할 옵티마이저. 옵션: 'adamw', 'sgd', 'nadam', 'radam', 'rmsprop'
  lr: 0.001                     # 옵티마이저의 학습률.
  weight_decay: 0.0001             # AdamW 옵티마이저의 가중치 감쇠(Weight Decay) 값.
  loss_function: 'CrossEntropyLoss' # 사용할 손실 함수. 옵션: 'CrossEntropyLoss', 'BCEWithLogitsLoss', 'FocalLoss'
  label_smoothing: 0.1            # 레이블 스무딩(Label Smoothing) 값. 0.0은 비활성화. (과적합 방지, 모델 일반화 성능 향상)
  # --- 학습률 Warmup 설정 ---
  warmup:
    enabled: false               # true: Warmup 사용, false: 사용 안 함
    epochs: 5                   # Warmup을 진행할 에포크 수
    start_lr: 0.00001           # Warmup 시작 시의 학습률 (선형증가)

  # bce_pos_weight: 'auto'        # 'BCEWithLogitsLoss' 사용 시 양성 클래스 가중치. 'auto'로 설정 시 자동 계산, 특정 값(예: 9.0)으로 수동 설정 가능. (num_labels=2여도 코드가 자동으로 [B, 1]로 변환하여 처리)
  # FocalLoss 하이퍼파라미터 (loss_function이 'FocalLoss'일 때 사용)
  # focal_loss_alpha: 0.5          # 클래스 불균형 조절. (0.5: 균등, >0.5: Defect 중요도 상승(Recall 향상), <0.5: Normal 중요도 상승(Precision 향상))
  # focal_loss_gamma: 2.0           # 학습 집중도 조절. (0: 일반 CE Loss, >0: 어려운 샘플에 집중(과적합 완화), 값이 클수록 집중도 상승)
  # 사용할 학습률 스케줄러를 설정합니다.
  scheduler: 'cosineannealinglr' # 옵션: 'multisteplr', 'cosineannealinglr', 'none'
  scheduler_params:
    # CosineAnnealingLR: T_max (주기, 보통 epochs), eta_min (최소 학습률)
    T_max: 90
    eta_min: 0.00005
  best_model_criterion: 'val_loss'  # 최고 모델 저장 기준. 옵션: 'val_loss', 'F1_average', 'F1_Normal', 'F1_Defect'.

# training_run:
#   epochs: 90
#   batch_size: 256
#   pre_trained: false
#   optimizer: 'sgd'
#   loss_function: 'BCEWithLogitsLoss' # num_labels=2여도 코드가 자동으로 [B, 1]로 변환하여 처리
#   bce_pos_weight: 'auto'
#   lr: 0.1
#   momentum: 0.9
#   weight_decay: 0.0001
#   scheduler: 'multisteplr'
#   milestones: [30, 60, 80]
#   gamma: 0.1
#   best_model_criterion: 'val_loss'  # 최고 모델 저장 기준. 옵션: 'val_loss', 'F1_average', 'F1_Normal', 'F1_Defect'.

# training_run:
#   epochs: 90
#   batch_size: 256
#   pre_trained: false
#   optimizer: 'adamw'
#   loss_function: 'CrossEntropyLoss' # num_labels=2여도 코드가 자동으로 [B, 1]로 변환하여 처리
#   # bce_pos_weight: 'auto'
#   lr: 0.0001
#   # momentum: 0.9
#   weight_decay: 0.01
#   scheduler: 'multisteplr'
#   milestones: [30, 60, 80]
#   gamma: 0.1
#   best_model_criterion: 'val_loss'  # 최고 모델 저장 기준. 옵션: 'val_loss', 'F1_average', 'F1_Normal', 'F1_Defect'.

# =============================================================================
# 3. 훈련 하이퍼파라미터 (baseline.py 전용)
# =============================================================================
# training_baseline:
#   epochs: 90                    # 훈련할 총 에포크 수.
#   batch_size: 256               # 훈련 및 평가 시 사용할 배치 크기.
#   pre_trained: false            # true: ImageNet 사전 훈련 가중치 사용, false: 무작위 초기화 가중치 사용
#   lr: 0.001
#   optimizer: 'adamw'            # 사용할 옵티마이저. 옵션: 'adamw', 'sgd'
#   loss_function: 'CrossEntropyLoss' # 사용할 손실 함수. 옵션: 'CrossEntropyLoss', 'BCEWithLogitsLoss'
#   # bce_pos_weight: 'auto'        # 'BCEWithLogitsLoss' 사용 시 양성 클래스 가중치. 'auto'로 설정 시 자동 계산, 특정 값(예: 9.0)으로 수동 설정 가능. (num_labels=2여도 코드가 자동으로 [B, 1]로 변환하여 처리)
#   # 사용할 학습률 스케줄러를 설정합니다.
#   scheduler: 'cosineannealinglr'      # 옵션: 'multisteplr', 'cosineannealinglr', 'none'
#   scheduler_params:
#     # CosineAnnealingLR: T_max (주기, 보통 epochs), eta_min (최소 학습률)
#     T_max: 90
#     eta_min: 0.000001
#   best_model_criterion: 'val_loss'  # 최고 모델 저장 기준. 옵션: 'val_loss', 'F1_average', 'F1_Normal', 'F1_Defect'.

# training_baseline:
#   epochs: 90                    # 훈련할 총 에포크 수.
#   batch_size: 256               # 훈련 및 평가 시 사용할 배치 크기.
#   pre_trained: false             # true: ImageNet 사전 훈련 가중치 사용, false: 무작위 초기화 가중치 사용
#   optimizer: 'sgd'              # 사용할 옵티마이저. 옵션: 'adamw', 'sgd'
#   loss_function: 'BCEWithLogitsLoss' # 사용할 손실 함수. 옵션: 'CrossEntropyLoss', 'BCEWithLogitsLoss'. (num_labels=2여도 코드가 자동으로 [B, 1]로 변환하여 처리)
#   bce_pos_weight: 'auto'        # 'BCEWithLogitsLoss' 사용 시 양성 클래스 가중치. 'auto'로 설정 시 자동 계산, 특정 값(예: 9.0)으로 수동 설정 가능.
#   lr: 0.1                       # 옵티마이저의 학습률.
#   momentum: 0.9                 # SGD 옵티마이저의 모멘텀 값.
#   weight_decay: 0.0001          # 옵티마이저의 가중치 감쇠(Weight Decay) 값.
#   scheduler: 'multisteplr'      # 사용할 학습률 스케줄러. 옵션: 'multisteplr', 'cosineannealinglr', 'none'
#   # scheduler_params:
#     # CosineAnnealingLR: T_max (주기, 보통 epochs), eta_min (최소 학습률)
#     # T_max: 90
#     # eta_min: 0.000001
#   milestones: [30, 60, 80]      # MultiStepLR 스케줄러에서 학습률을 감소시킬 에포크 지점.
#   gamma: 0.1                    # MultiStepLR 스케줄러에서 학습률에 곱할 값.
#   best_model_criterion: 'val_loss'  # 최고 모델 저장 기준. 옵션: 'val_loss', 'F1_average', 'F1_Normal', 'F1_Defect'.


# =============================================================================
# 4. 모델 아키텍처 파라미터 (run.py 전용)
# =============================================================================
model:
  # --- 이미지 및 인코더 설정 ---
  img_size: 224                # 모델에 입력하기 전 이미지의 리사이즈 크기 (정사각형).
  in_channels: 3               # 입력 이미지의 채널 수. 옵션: 1 (흑백), 3 (컬러).
  patch_size: 56              # 이미지를 나눌 정사각형 패치의 크기. `img_size`는 `patch_size`로 나누어 떨어져야 합니다.
  stride: 56                   # 패치를 추출할 때의 보폭(stride). `patch_size`보다 작으면 오버랩됩니다.
  cnn_feature_extractor:
    # 이미지 패치에서 특징을 추출할 CNN 모델을 선택합니다.
    # 사용 가능한 옵션:
    # - 'resnet18_layer1': ResNet18의 layer1까지 사용. 64
    # - 'resnet18_layer2': ResNet18의 layer2까지 사용. 128

    # - 'mobilenet_v3_small_feat1': MobileNetV3-Small의 features[1]까지 사용. 16
    # - 'mobilenet_v3_small_feat3': MobileNetV3-Small의 features[3]까지 사용. 24
    # - 'mobilenet_v3_small_feat4': MobileNetV3-Small의 features[4]까지 사용. 40

    # - 'efficientnet_b0_feat2': EfficientNet-B0의 features[2]까지 사용 (기본). 24
    # - 'efficientnet_b0_feat3': EfficientNet-B0의 features[3]까지 사용. 40


    # - 'mobilenet_v4_feat1': MobileNetV4-Conv-Small의 features[0]까지 사용. 32
    # - 'mobilenet_v4_feat2': MobileNetV4-Conv-Small의 features[1]까지 사용. 48
    # - 'mobilenet_v4_feat3': MobileNetV4-Conv-Small의 features[2]까지 사용. 64
    # - 'mobilenet_v4_feat4': MobileNetV4-Conv-Small의 features[3]까지 사용. 96
    # - 'mobilenet_v4_feat5': MobileNetV4-Conv-Small의 features[4]까지 사용. 160

    name: 'efficientnet_b0_feat2'    

  # --- 디코더 및 임베딩 설정 ---
  featured_patch_dim: 24     # CNN 특징 추출기가 각 이미지 패치에서 추출하는 특징 벡터의 차원.
  emb_dim: 24                # 트랜스포머 모델 내부에서 사용하는 통일된 임베딩 차원.
  num_heads: 2               # 멀티헤드 어텐션에서 사용할 헤드의 수. `emb_dim`은 `num_heads`로 나누어 떨어져야 합니다.
  num_decoder_layers: 4      # 모델 내부의 디코더 레이어 수.
  num_decoder_patches: 1     # 디코더에서 사용할 학습 가능한 쿼리(패치)의 수. 모델의 표현력을 조절합니다.
  attn_pooling: true         # true: 어텐션 풀링으로 동적 쿼리 생성, false: 기존의 고정 쿼리 방식 사용.
  decoder_ff_ratio: 2        # 트랜스포머의 피드포워드 네트워크(FFN) 내부 차원을 결정하는 비율 (decoder_ff_dim = emb_dim * decoder_ff_ratio).
  dropout: 0.0               # 모델 내부에 적용될 드롭아웃 비율 (분류기, FFN, 어텐션 출력에 적용).
  positional_encoding: true  # 이미지 패치 시퀀스 (인코더 출력)에 위치 인코딩 추가 여부. False로 설정하면 위치 정보를 사용하지 않습니다.
  res_attention: true        # 디코더 레이어 간에 어텐션 스코어를 전달하는 잔차 어텐션 사용 여부.
  save_attention: true       # 추론 시 어텐션 맵을 저장할지 여부. True로 설정하면 시각화에 사용할 수 있습니다.
  num_plot_attention: 20     # 어텐션 맵을 시각화하여 저장할 최대 샘플 수.

# =============================================================================
# 5. Baseline 모델 설정 (baseline.py 전용)
# =============================================================================
baseline:
  # 사용할 baseline 모델의 이름을 지정합니다.
  # 사용 가능한 옵션: 'resnet18', 'efficientnet_b0', 'mobilenet_v4', 'xie2019'
  model_name: 'mobilenet_v4'