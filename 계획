1차 시도: 바닐라 efficientnet_b0_feat2 85.46
2차: 1차의 qam end 0.5 -> 0.0 (1차 대비 성능 향상. 이후 차시부터 qam=0.0 사용.) 86.23
3차: 2차의 n_heads 4->2 (2차 대비 성능향상. 이후 차시부터 n_heads =2 사용.) 86.38
4차: 3차의 positional_encoding 끄기 (3차 대비 성능 하락. 이후 차시부터 positional encoding true 고정) 85.54
5차: 3차에 스케줄프리 도입 (성능 소폭 상승.) 86.62
6차: 5차의 AdamW 스케줄프리 -> SGD 스케줄프리(모멘텀0.9) 70퍼대 
7차: 5차의 efficientnet_b0_feat2 -> mobilenet_v3_small_feat1 80.23
8차: 5차의 efficientnet_b0_feat2 -> resnet18_layer1 84.92
9차: 5차의 데이터 수를 늘리고 에포크도 늘리기. 0.01 -> 0.1, 30 ->50 (9차는 30에포크 이전에 이미 5차보다 성능이 좋았음. 따라서 데이터 개수가 늘수록 성능 향상됨.) 87.18
10차: 5차의 데이터 수를 0.01 -> 0.3, 배치사이즈 8 -> 16.   87.63 (과적합 너무너무 심함. 거의 10에포크 이후로는 최고성능 갱신이 어려워지고 진동도 심함.)

11차:
0.3 -> 0.1 데이터 비율.    202850    85.89
배치 사이즈 16 -> 32
classifier단에 중간층 최초 삽입
디코더 쿼리 패치 개수 계산식을 레이블 개수와 동일시하여 각 쿼리패치가 각 레이블 특징을 학습하도록 유도 (패치 개수 1-> 2)
qam을 기존에는 패치 순서마다 고정된 선형값을 적용(아마 시계열인 것과 영향..?)이었지만, 각 패치마다 지정범위의 유니폼 분포에서 랜덤값을 마스킹 확률로 사용.
qam 0.1~0.4 
학습 결과 epoch당 val acc를 확인해보니까 들쭉날쭉 학습 안정성이 낮아졌다.

12차: 11차에서 qam 0.1~0.4 -> qam 0.0~0.0 으로 수정함.  212056   86.71
실험결과, epoch당 val acc를 확인해보니까 12차가 11차보다 학습 안정성이 높다.
따라서 qam이 효과가 없다고 판단하여 qam 사용 안 하기로 함.

13차: 12차의 데이터 비율 0.1 -> 0.3   87.86
(10차와 다른 점은 배치 사이즈 16 -> 32, 분류단에 중간층 삽입.)
성능 나쁘지 않음.

14차: 13차의 qam 0.0 -> 0.1 추가 87.75
qam 고정 비율로 사용 (일반화 성능 도모)
그 결과 성능은 qam 0.0인 13차와 비슷해보였지만 val acc 그래프를 보니 학습 불안정성이 너무 커졌다.
따라서 앞으로 qam 은 0.0으로 고정해둬야겠다.

15차: 13차에서 in_channels, 트랜스폼 수정.  021944 
지금까지의 in_channnels 코드는 변수값이 3일 때에 내 의도처럼 입력 이미지의 rgb 채널을 그대로 사용하는 게 아니라, 그레이스케일을 3개 채널로 복사하고 사용하는 방식이었다...
in_channels가 3일 때, 내 의도대로 입력 이미지의 rgb채널을 그대로 cnn에 입력하도록 수정했다.
그리고 in_channels가 3일 때에 기존에는 흑백 정규화가 사용되던 오류를 sewer-ml 공식 레포의 트랜스폼을 사용 (i_channels = 1일 때는 커스텀 트랜스폼)하도록 수정했다. (어그멘테이션 -> to텐서 -> 정규화 순서 )

16차: 15차에서 데이터를 0.3에서 1.0 으로 수정.


17차: run_no_cats로 15차에서 CatsDecoder만 제외하고 실험 진행


멀티 헤드 개수 늘리기 (다양한 종류의 피처를 학습 가능. emb_dim은 고정한 채로 멀티 헤드 개수만 늘리면 각 헤드가 충분한 정보를 못 담고 성능하락 가능)
디코더 레이어 늘리기 (피처를 점진적 추상화 도모. res_attention으로 과적합 및 기울기 소실 예방 가능)



mobilenet_v3_small_feat1 (채널3)
2025-10-19 22:45:34,660 - INFO -   - Encoder (PatchConvEncoder): 1,664 개
2025-10-19 22:45:34,660 - INFO -   - Decoder (CatsDecoder):      10,200 개
2025-10-19 22:45:34,660 - INFO -   - Classifier (Linear Head):   50 개
2025-10-19 22:45:34,660 - INFO -   - 총 파라미터:                  11,914 개





efficientnet_b0_feat2 (채널3)
2025-10-19 04:50:15,348 - INFO -   - Encoder (PatchConvEncoder): 19,138 개
2025-10-19 04:50:15,348 - INFO -   - Decoder (CatsDecoder):      10,200 개
2025-10-19 04:50:15,348 - INFO -   - Classifier (Linear Head):   50 개
2025-10-19 04:50:15,348 - INFO -   - 총 파라미터:                  29,388 개


resnet18_layer1 (3채널)
2025-10-19 23:36:13,126 - INFO -   - Encoder (PatchConvEncoder): 159,112 개
2025-10-19 23:36:13,126 - INFO -   - Decoder (CatsDecoder):      10,200 개
2025-10-19 23:36:13,128 - INFO -   - Classifier (Linear Head):   50 개
2025-10-19 23:36:13,128 - INFO -   - 총 파라미터:                  169,362 개



의 in_channels 3 -> 1



진짜 마지막 실험 때는 피처추출단에 바로 분류단을 연결시켜서 성능을 확인해봐야겠다. 이게 내 꺼보다 성능이 낮아야만 해.



헤드 개수 느는 건 파라미터랑 영향 없음.
아래에 분류단 파라미터 는 건 내가 중간층 삽입했기 때문이다.


디코더 레이어 2
2025-10-21 00:16:52,281 - INFO -   - Encoder (PatchConvEncoder): 19,138 개
2025-10-21 00:16:52,281 - INFO -   - Decoder (CatsDecoder):      10,224 개
2025-10-21 00:16:52,281 - INFO -   - Classifier (Linear Head):   1,277 개
2025-10-21 00:16:52,281 - INFO -   - 총 파라미터:                  30,639 개


디코더 레이어 4
2025-10-21 00:17:57,118 - INFO -   - Encoder (PatchConvEncoder): 19,138 개
2025-10-21 00:17:57,118 - INFO -   - Decoder (CatsDecoder):      18,816 개
2025-10-21 00:17:57,118 - INFO -   - Classifier (Linear Head):   1,277 개
2025-10-21 00:17:57,118 - INFO -   - 총 파라미터:                  39,231 개