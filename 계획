1차 시도: 바닐라 efficientnet_b0_feat2 85.46
2차: 1차의 qam end 0.5 -> 0.0 (1차 대비 성능 향상. 이후 차시부터 qam=0.0 사용.) 86.23
3차: 2차의 n_heads 4->2 (2차 대비 성능향상. 이후 차시부터 n_heads =2 사용.) 86.38
4차: 3차의 positional_encoding 끄기 (3차 대비 성능 하락. 이후 차시부터 positional encoding true 고정) 85.54
5차: 3차에 스케줄프리 도입 (성능 소폭 상승.) 86.62
6차: 5차의 AdamW 스케줄프리 -> SGD 스케줄프리(모멘텀0.9) 70퍼대 
7차: 5차의 efficientnet_b0_feat2 -> mobilenet_v3_small_feat1 80.23
8차: 5차의 efficientnet_b0_feat2 -> resnet18_layer1 84.92
9차: 5차의 데이터 수를 늘리고 에포크도 늘리기. 0.01 -> 0.1, 30 ->50 (9차는 30에포크 이전에 이미 5차보다 성능이 좋았음. 따라서 데이터 개수가 늘수록 성능 향상됨.) 87.18
10차: 5차의 데이터 수를 0.01 -> 0.3, 배치사이즈 8 -> 16.   87.63 (과적합 너무너무 심함. 거의 10에포크 이후로는 최고성능 갱신이 어려워지고 진동도 심함.)

11차:
0.3 -> 0.1 데이터 비율.    202850    85.89
배치 사이즈 16 -> 32
classifier단에 중간층 최초 삽입
디코더 쿼리 패치 개수 계산식을 레이블 개수와 동일시하여 각 쿼리패치가 각 레이블 특징을 학습하도록 유도 (패치 개수 1-> 2)
qam을 기존에는 패치 순서마다 고정된 선형값을 적용(아마 시계열인 것과 영향..?)이었지만, 각 패치마다 지정범위의 유니폼 분포에서 랜덤값을 마스킹 확률로 사용.
qam 0.1~0.4 
학습 결과 epoch당 val acc를 확인해보니까 들쭉날쭉 학습 안정성이 낮아졌다.

12차: 11차에서 qam 0.1~0.4 -> qam 0.0~0.0 으로 수정함.  212056   86.71
실험결과, epoch당 val acc를 확인해보니까 12차가 11차보다 학습 안정성이 높다.
따라서 qam이 효과가 없다고 판단하여 qam 사용 안 하기로 함.

13차: 12차의 데이터 비율 0.1 -> 0.3   87.86
(10차와 다른 점은 배치 사이즈 16 -> 32, 분류단에 중간층 삽입.)
성능 나쁘지 않음.

14차: 13차의 qam 0.0 -> 0.1 추가 87.75
qam 고정 비율로 사용 (일반화 성능 도모)
그 결과 성능은 qam 0.0인 13차와 비슷해보였지만 val acc 그래프를 보니 학습 불안정성이 너무 커졌다.
따라서 앞으로 qam 은 0.0으로 고정해둬야겠다.

15차: 13차에서 in_channels, 트랜스폼 수정.  021944 
지금까지의 in_channnels 코드는 변수값이 3일 때에 내 의도처럼 입력 이미지의 rgb 채널을 그대로 사용하는 게 아니라, 그레이스케일을 3개 채널로 복사하고 사용하는 방식이었다...
in_channels가 3일 때, 내 의도대로 입력 이미지의 rgb채널을 그대로 cnn에 입력하도록 수정했다.
그리고 in_channels가 3일 때에 기존에는 흑백 정규화가 사용되던 오류를 sewer-ml 공식 레포의 트랜스폼을 사용 (i_channels = 1일 때는 커스텀 트랜스폼)하도록 수정했다. (어그멘테이션 -> to텐서 -> 정규화 순서 )
Train Acc: 89.83%
Test Acc: 89.00%
F1 Score for 'Normal': 0.8937

16차: 15차에서 데이터를 0.3에서 1.0 으로 수정.
Train Acc: 90.52%
Test Acc: 89.67%
F1 Score for 'Normal': 0.9038

17차: run_no_cats로 15차에서 CatsDecoder만 제외하고, 인코더랑 분류단만 연결하여 실험 진행
Train Acc: 91.42%
Test Acc: 90.29%
F1 Score for 'Normal': 0.9065


---- 10.23 랩미팅-----
보고: 16차 결과가 베스트 모델.
피드백: 디코더 패치 개수를 1개로.
---------------------

18차: 16차에서 디코더 패치 개수만 1로. 물론 num_labels는 여전히 2로써 분리시킴.
성능이 비슷함..

19차 89.69 : 18차에서  
attn_pooling 추가: 러너블 쿼리를 임베딩시키고(시드쿼리) 인코더 출력시퀀스와 어텐션하여 어텐션 벨류 만들고, 그걸 디코더블럭의 쿼리로 사용
스케줄프리 끄고, 코사인 스케줄러 도입
데이터 비율 1.0에서 0.1로

20차 89.08 : 19차에서 attn_pooling 제거 89.18




21차: 19차에서
self.learnable_queries = nn.Parameter(0.5*torch.randn(num_decoder_patches, featured_patch_dim))
-> 
self.learnable_queries = nn.Parameter(torch.empty(num_decoder_patches, featured_patch_dim))
별차이 없음.
Train Acc: 89.01%
Val Acc: 89.17% 
F1: 0.8917
2025-10-24 21:48:41,678 - INFO - 모델 파라미터 수:
2025-10-24 21:48:41,678 - INFO -   - Encoder (PatchConvEncoder):   19,138 개
2025-10-24 21:48:41,678 - INFO -     - conv_front (CNN Backbone):  19,090 개
2025-10-24 21:48:41,678 - INFO -     - 1x1_conv (Channel Proj):    0 개
2025-10-24 21:48:41,678 - INFO -     - norm (LayerNorm):           48 개
2025-10-24 21:48:41,678 - INFO -   - Decoder (CatsDecoder):        10,200 개
2025-10-24 21:48:41,678 - INFO -     - Embedding Layer (W_feat2emb):    600 개
2025-10-24 21:48:41,678 - INFO -     - Learnable Queries:               24 개
2025-10-24 21:48:41,678 - INFO -     - Positional Encoding (PE):        384 개
2025-10-24 21:48:41,678 - INFO -     - Decoder Layers (Cross-Attention): 8,592 개
2025-10-24 21:48:41,678 - INFO -     - Projection4Classifier:      600 개
2025-10-24 21:48:41,678 - INFO -   - Classifier (Projection MLP):  353 개
2025-10-24 21:48:41,678 - INFO -   - 총 파라미터:                  29,691 개


; 22차: 21차에서
; patch_size 120 -> 80 (Positional Encoding만 바뀜: 384-> 864)
; 별차이 없음.

; 23차: 21차에서
; emb_dim 24 -> 48 (임베딩 차원): 모델의 기본 체급. 늘리면 표현력이 크게 증가합니다.
; num_decoder_layers 2-> 4 (레이어 수): 모델의 깊이. 더 깊게 쌓으면 더 복잡한 관계를 학습할 수 있습니다.
; num_heads 2-> 4 (어텐션 헤드 수): 다양한 관점에서 특징을 볼 수 있는 능력.
; decoder_ff_ratio 2-> 4 (FFN 비율): FFN의 복잡도를 높여 표현력을 보강합니다
; 2025-10-24 23:48:22,303 - INFO - 모델 파라미터 수:
; 2025-10-24 23:48:22,318 - INFO -   - Encoder (PatchConvEncoder):   19,138 개
; 2025-10-24 23:48:22,318 - INFO -     - conv_front (CNN Backbone):  19,090 개
; 2025-10-24 23:48:22,318 - INFO -     - 1x1_conv (Channel Proj):    0 개
; 2025-10-24 23:48:22,318 - INFO -     - norm (LayerNorm):           48 개
; 2025-10-24 23:48:22,318 - INFO -   - Decoder (CatsDecoder):        97,824 개
; 2025-10-24 23:48:22,318 - INFO -     - Embedding Layer (W_feat2emb):    1,200 개   emb_dim이 2배 증가해서.
; 2025-10-24 23:48:22,318 - INFO -     - Learnable Queries:               24 개
; 2025-10-24 23:48:22,318 - INFO -     - Positional Encoding (PE):        768 개     emb_dim이 2배 증가해서.
; 2025-10-24 23:48:22,318 - INFO -     - Decoder Layers (Cross-Attention): 94,656 개
; 2025-10-24 23:48:22,319 - INFO -     - Projection4Classifier:      1,176 개        emb_dim이 2배 증가해서.
; 2025-10-24 23:48:22,319 - INFO -   - Classifier (Projection MLP):  353 개
; 2025-10-24 23:48:22,319 - INFO -   - 총 파라미터:                  117,315 개
; 별차이 없음.


; --- 작전 변경 ---
; 목표:
;     데이터 비율을 0.01로 고정하고, train acc를 100%에 가깝도록 과적합부터 시켜보기.
; 지금까지의 문제점:
;     에포크가 진행될 때마다 loss가 감소하긴 하지만, train acc와 val acc가 89%대에서 계속 정체함.
;     train acc가 100%에 수렴하지 않는 지금의 현상은 모델 자체의 성능이 부족하다고 판단함.
;     일단은 과적합을 시켜놓고서 추후에 일반화를 도모하기로 방향성 변경.
; 방법:
;     cnn 백본들을 바꿔보면서 train acc가 90% 이상인 모델들을 찾기. 다시 말해, 피지컬이 받쳐주는 백본 찾기.
; 밑 실험들은 데이터 비율 0.01
; ----------------

; 24차: 21차에서 efficientnet_b0_feat2 -> efficientnet_b0_feat3
; Train Acc: 92.30%
; Test Acc: 88.23%
; F1 Score for 'Normal': 0.8909
; 2025-10-25 01:33:26,370 - INFO - 모델 파라미터 수:
; 2025-10-25 01:33:26,370 - INFO -   - Encoder (PatchConvEncoder):   66,762 개
; 2025-10-25 01:33:26,370 - INFO -     - conv_front (CNN Backbone):  65,730 개
; 2025-10-25 01:33:26,370 - INFO -     - 1x1_conv (Channel Proj):    984 개
; 2025-10-25 01:33:26,370 - INFO -     - norm (LayerNorm):           48 개
; 2025-10-25 01:33:26,370 - INFO -   - Decoder (CatsDecoder):        10,200 개
; 2025-10-25 01:33:26,370 - INFO -     - Embedding Layer (W_feat2emb):    600 개
; 2025-10-25 01:33:26,370 - INFO -     - Learnable Queries:               24 개
; 2025-10-25 01:33:26,370 - INFO -     - Positional Encoding (PE):        384 개
; 2025-10-25 01:33:26,370 - INFO -     - Decoder Layers (Cross-Attention): 8,592 개
; 2025-10-25 01:33:26,370 - INFO -     - Projection4Classifier:      600 개
; 2025-10-25 01:33:26,370 - INFO -   - Classifier (Projection MLP):  353 개
; 2025-10-25 01:33:26,370 - INFO -   - 총 파라미터:                  77,315 개

; 25차: 24차에서 dropout 0.1 -> 0.0
; Train Acc: 93.54%
; Test Acc: 87.77%
; F1 Score for 'Normal': 0.8870
; 따라서 efficientnet_b0_feat3는 모델 피지컬은 충분하다고 판단.
; dropout 옵션 유무가 영향력 있다고 판단.

; 26차: 21차에서 efficientnet_b0_feat2 -> mobilenet_v3_small_feat1
; Train Acc: 82.46%
; Val Acc: 81.92%
; 너무 낮음.
; 2025-10-25 02:10:59,931 - INFO - 모델 파라미터 수:
; 2025-10-25 02:10:59,931 - INFO -   - Encoder (PatchConvEncoder):   1,664 개
; 2025-10-25 02:10:59,931 - INFO -     - conv_front (CNN Backbone):  1,208 개
; 2025-10-25 02:10:59,931 - INFO -     - 1x1_conv (Channel Proj):    408 개
; 2025-10-25 02:10:59,931 - INFO -     - norm (LayerNorm):           48 개
; 2025-10-25 02:10:59,931 - INFO -   - Decoder (CatsDecoder):        10,200 개
; 2025-10-25 02:10:59,931 - INFO -     - Embedding Layer (W_feat2emb):    600 개
; 2025-10-25 02:10:59,931 - INFO -     - Learnable Queries:               24 개
; 2025-10-25 02:10:59,931 - INFO -     - Positional Encoding (PE):        384 개
; 2025-10-25 02:10:59,931 - INFO -     - Decoder Layers (Cross-Attention): 8,592 개
; 2025-10-25 02:10:59,931 - INFO -     - Projection4Classifier:      600 개
; 2025-10-25 02:10:59,931 - INFO -   - Classifier (Projection MLP):  353 개
; 2025-10-25 02:10:59,931 - INFO -   - 총 파라미터:                  12,217 개


; 27차: 21차에서 efficientnet_b0_feat2 -> mobilenet_v3_small_feat3
; Train Acc: 89.46%
; Test Acc: 86.23%
; F1 Score for 'Normal': 0.8698
; 2025-10-25 02:21:55,863 - INFO - 모델 파라미터 수:
; 2025-10-25 02:21:55,863 - INFO -   - Encoder (PatchConvEncoder):   10,536 개
; 2025-10-25 02:21:55,863 - INFO -     - conv_front (CNN Backbone):  10,488 개
; 2025-10-25 02:21:55,863 - INFO -     - 1x1_conv (Channel Proj):    0 개
; 2025-10-25 02:21:55,863 - INFO -     - norm (LayerNorm):           48 개
; 2025-10-25 02:21:55,863 - INFO -   - Decoder (CatsDecoder):        10,200 개
; 2025-10-25 02:21:55,863 - INFO -     - Embedding Layer (W_feat2emb):    600 개
; 2025-10-25 02:21:55,863 - INFO -     - Learnable Queries:               24 개
; 2025-10-25 02:21:55,863 - INFO -     - Positional Encoding (PE):        384 개
; 2025-10-25 02:21:55,863 - INFO -     - Decoder Layers (Cross-Attention): 8,592 개
; 2025-10-25 02:21:55,863 - INFO -     - Projection4Classifier:      600 개
; 2025-10-25 02:21:55,863 - INFO -   - Classifier (Projection MLP):  353 개
; 2025-10-25 02:21:55,863 - INFO -   - 총 파라미터:                  21,089 개


; 28차: 21차에서 efficientnet_b0_feat2 -> mobilenet_v3_small_feat4
; Train Acc: 89.72%
; Test Acc: 87.00%
; F1 Score for 'Normal': 0.8807
; 2025-10-25 02:50:53,310 - INFO - 모델 파라미터 수:
; 2025-10-25 02:50:53,310 - INFO -   - Encoder (PatchConvEncoder):   25,256 개
; 2025-10-25 02:50:53,310 - INFO -     - conv_front (CNN Backbone):  24,224 개
; 2025-10-25 02:50:53,310 - INFO -     - 1x1_conv (Channel Proj):    984 개
; 2025-10-25 02:50:53,310 - INFO -     - norm (LayerNorm):           48 개
; 2025-10-25 02:50:53,310 - INFO -   - Decoder (CatsDecoder):        10,200 개
; 2025-10-25 02:50:53,310 - INFO -     - Embedding Layer (W_feat2emb):    600 개
; 2025-10-25 02:50:53,310 - INFO -     - Learnable Queries:               24 개
; 2025-10-25 02:50:53,310 - INFO -     - Positional Encoding (PE):        384 개
; 2025-10-25 02:50:53,310 - INFO -     - Decoder Layers (Cross-Attention): 8,592 개
; 2025-10-25 02:50:53,310 - INFO -     - Projection4Classifier:      600 개
; 2025-10-25 02:50:53,310 - INFO -   - Classifier (Projection MLP):  353 개
; 2025-10-25 02:50:53,310 - INFO -   - 총 파라미터:                  35,809 개

; 29차: 21차에서 efficientnet_b0_feat2 -> mobilenet_v3_small_feat5
; 2025-10-25 03:43:30,294 - INFO - 모델 파라미터 수:
; 2025-10-25 03:43:30,294 - INFO -   - Encoder (PatchConvEncoder):   82,520 개
; 2025-10-25 03:43:30,294 - INFO -     - conv_front (CNN Backbone):  81,488 개
; 2025-10-25 03:43:30,294 - INFO -     - 1x1_conv (Channel Proj):    984 개
; 2025-10-25 03:43:30,309 - INFO -     - norm (LayerNorm):           48 개
; 2025-10-25 03:43:30,309 - INFO -   - Decoder (CatsDecoder):        10,200 개
; 2025-10-25 03:43:30,309 - INFO -     - Embedding Layer (W_feat2emb):    600 개
; 2025-10-25 03:43:30,309 - INFO -     - Learnable Queries:               24 개
; 2025-10-25 03:43:30,309 - INFO -     - Positional Encoding (PE):        384 개
; 2025-10-25 03:43:30,309 - INFO -     - Decoder Layers (Cross-Attention): 8,592 개
; 2025-10-25 03:43:30,309 - INFO -     - Projection4Classifier:      600 개
; 2025-10-25 03:43:30,309 - INFO -   - Classifier (Projection MLP):  353 개
; 2025-10-25 03:43:30,309 - INFO -   - 총 파라미터:                  93,073 개
; 9만개면, 이피션트넷 앞단에 리니어만 연결한 모델의 파라미터수랑 비슷한데, 그러면 경량화 의미가 없다. 따라서 진행 안 함.


30차: 21차의 드롭아웃 0.1 -> 0.0, 데이터비율 0.1 -> 0.01
Train Acc: 89.01%
Test Acc: 87.62%
F1 Score for 'Normal': 0.8836
; 아래는 데이터 비율 0.1짜리 21차 꺼
; Train Acc: 89.01%
; Val Acc: 89.17% 
; F1: 0.8917
드롭아웃 0.0이 0.1보다 안 좋은 것 같다.


; 31차: 25차에서 efficientnet_b0_feat3 -> mobilenet_v3_small_feat4 30에포크
; Train Acc: 90.70%
; Test Acc: 87.46%
; F1 Score for 'Normal': 0.8838
; 2025-10-25 11:55:37,666 - INFO - 모델 파라미터 수:
; 2025-10-25 11:55:37,666 - INFO -   - Encoder (PatchConvEncoder):   25,256 개
; 2025-10-25 11:55:37,666 - INFO -     - conv_front (CNN Backbone):  24,224 개
; 2025-10-25 11:55:37,666 - INFO -     - 1x1_conv (Channel Proj):    984 개
; 2025-10-25 11:55:37,666 - INFO -     - norm (LayerNorm):           48 개
; 2025-10-25 11:55:37,666 - INFO -   - Decoder (CatsDecoder):        10,200 개
; 2025-10-25 11:55:37,666 - INFO -     - Embedding Layer (W_feat2emb):    600 개
; 2025-10-25 11:55:37,666 - INFO -     - Learnable Queries:               24 개
; 2025-10-25 11:55:37,666 - INFO -     - Positional Encoding (PE):        384 개
; 2025-10-25 11:55:37,666 - INFO -     - Decoder Layers (Cross-Attention): 8,592 개
; 2025-10-25 11:55:37,666 - INFO -     - Projection4Classifier:      600 개
; 2025-10-25 11:55:37,666 - INFO -   - Classifier (Projection MLP):  353 개
; 2025-10-25 11:55:37,666 - INFO -   - 총 파라미터:                  35,809 개


; 32차: 30차의 CnnFeatureExtractor forward 마지막에 SEBlock 추가.
; train acc가 89를 넘겨야 의미있는 시도가 된다.
; Train Acc: 88.78%
; Test Acc: 87.31%
; F1 Score for 'Normal': 0.8805
; 따라서 seblock 추가는 폐기


; 33차: 30차에 cutmix, fpn 추가
; Train Acc: 84.88%
; Test Acc: 87.46%
; F1 Score for 'Normal': 0.8863
; cutmix와 fpn을 적용하니까 train acc보다 val acc가 훨씬 높은 현상이 발생함.
; CutMix가 훈련 시에만 적용되고, 검증 시에는 적용되지 않기 때문으로 추측.
; fpn은 저수준 특징 (Low-level): features[:2], 고수준 특징 (High-level): features[2:3]을 기존처럼 구하고, 두 특징의 해상도와 채널 수를 맞춘 뒤, 이를 더합니다 (feat1_upsampled + feat2). 덕분에 더 다채롭게 특징을 뽑아서 성능개선에 영향 줄 듯.


; 34차: 33차의 에포크를 30 -> 60
; 만약 33차보다 성능이 좋다면, 에포크 이슈일 수 있으니까 30차꺼를 에포크 30 -> 60으로 해보자.
; Train Acc: 85.87%
; Test Acc: 88.31%
; F1 Score for 'Normal': 0.8925


35차: 30차의 에포크를 60으로 수정
Train Acc: 91.77%
Test Acc: 88.08%
F1 Score for 'Normal': 0.8892
; 아래는 30차
; Train Acc: 89.01%
; Test Acc: 87.62%
; F1 Score for 'Normal': 0.8836
이거이거 에포크나 스케줄러가 너무 중요해보인다....
일단 에포크는 30보다 커야 하는 게 맞다.


; 36차: 30차의 CosineAnnealingLR를
; CosineAnnealingWarmRestarts (T_0=10, T_mult=2, 에포크 70 (10 에포크부터, 2배의 에포크기간동안 코사인 주기.)) 으로 수정.
; F1 average 기준 베스트 모델 저장에서 F1 Normal 기준으로 변경
; Train Acc: 92.42%
; Test Acc: 87.38%
; F1 Score for 'Normal': 0.8815
; 35차랑 36차의 차이점이 스케줄러랑 베스트 모델 저장 기준이다.
; 근데 스케줄러는 35차의 CosineAnnealingLR이 Test Acc랑 F1 normal이 더 높다.


; 37차는 36차에 드롭아웃 0.1 추가.
; Train Acc: 90.15%
; Test Acc: 88.23%
; F1 Score for 'Normal': 0.8913
; 35차보다는 36차가 낫네..


38차: 35차의 F1 average 기준 베스트 모델 저장에서 F1 Normal 기준으로 변경
Train Acc: 91.95%
Test Acc: 87.15%
F1 Score for 'Normal': 0.8833

39차는 38차에 드롭아웃 0.1 추가
Train Acc: 89.39%
Test Acc: 88.69%
F1 Score for 'Normal': 0.8949

; 아래는 데이터 비율 0.1짜리 21차 꺼
; Train Acc: 89.01%
; Val Acc: 89.17% 
; F1: 0.8917


40차: 39차 가중치로 테스트셋 전체를 추론. (테스트셋 0.01 -> 1.0)
Test Acc: 87.13%,
F1 Score for 'Normal': 0.8770


--- 39차를 메인으로 삼기로 결정---
39차 정보
트레인, 벨리드, 테스트셋 0.01 비율
에포크 60
CosineAnnealingLR
efficientnet_b0_feat2
best_model_criterion: F1_Normal
--------------------------------


따라서 데이터를 늘릴 필요가 있어보인다.
또 다른 옵션으로는... 정규화 강도 높이기?


41차: 40차의 트레인, 벨리드 데이터 비율 0.01 -> 0.1
21차랑 40차랑 다른점은 테스트비율 0.1 vs 1.0, best_model_criterion: F1_average vs F1_Normal, 에포크 30 vs 60
Train Acc: 90.51%
Test Acc: 89.98%
F1 Score for 'Normal': 0.9034
따라서 학습, 벨리드 비율을 0.01에서 0.1로 증가시키니까 Test Acc, F1 Score for 'Normal' 가 증가함을 확인했다.


42차: 41차의 트레인, 벨리드 데이터 비율 0.1 -> 1.0
41/60 epoch에서 중단됨.
41차 Train Acc: 90.54%
41차 Val Acc: 90.70%
41차까지의 베스트 F1 Normal: 0.9137


43차: 42차를 60/60 epoch 완수
Train Acc: 91.25%
Test Acc: 91.70%
F1 Score for 'Normal': 0.9208
0.32ms
67.81 MB


44차: 43차에서 res_attention 켜기
Train Acc: 91.25%
Test Acc: 91.63%
F1 Score for 'Normal': 0.9202
0.32ms
67.81 MB
따라서 res_attention은 의미가 없다. 앞으로도 끄기.


45차: 43차에서 attn_pooling 끄기
Train Acc: 90.97%
Test Acc: 91.23%
F1 Score for 'Normal': 0.9167
0.32ms
67.81 MB
43차보다 성능이 낮으므로, attn_pooling은 효과적이다.


46차: 43차 모델로 tapnew 실험.
Train Acc: 89.06%
Test Acc: 87.32%
F1 Score for 'Normal': 0.8782


47차: 43차 모델로 tap 실험.
Train Acc: 97.28%
Test Acc: 97.83%
F1 Score for 'Normal': 0.9783


48차: baseline.py의 resnet18로 Sewer-ML 학습
Train Acc: 99.97%
Test Acc: 91.75%
F1 Score for 'Normal': 0.9212


49차: baseline.py의 efficientnet_b0로 Sewer-ML 학습
Train Acc: 99.23%
Test Acc: 93.35%
총 파라미터: 4,010,110 개
F1 Score for 'Normal': 0.9363


50차 진행 중: baseline.py의 mobilenet_v4로 Sewer-ML 학습
총 파라미터: 2,495,586 개














xie2019
pth File size: 34.9MB
총 파라미터: 9,159,681 개
연산량 (MACs): 1.43 GMACs per sample
연산량 (FLOPs): 2.87 GFLOPs per sample
샘플 당 평균 Forward Pass 시간: 0.2ms (100회 반복)
샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 65.77 MB

-> 224해상도를 480으로 수정
'./inference_results/inference_xie2019_binary_val_20251107_153449.log'
2025-11-07 15:34:49,957 - INFO - 연산량 (MACs): 6.56 GMACs per sample
2025-11-07 15:34:49,957 - INFO - 연산량 (FLOPs): 13.11 GFLOPs per sample
2025-11-07 15:34:50,025 - INFO - 샘플 당 평균 Forward Pass 시간: 0.57ms (100회 반복)
2025-11-07 15:34:50,026 - INFO - 샘플 당 최대 GPU 메모리 사용량: 144.14 MB


my model (43차)
pth File size: 0.16MB
총 파라미터: 29,691 개
연산량 (MACs): 0.42 GMACs per sample
연산량 (FLOPs): 0.84 GFLOPs per sample
샘플 당 평균 Forward Pass 시간: 0.69ms (100회 반복)
샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 61.07 MB

-> 480 리사이즈, 480 패치 버전
샘플 당 최대 GPU 메모리 사용량: 58.43 MB
샘플 당 평균 Forward Pass 시간: 0.66ms (100회 반복)


resnet18 (48차)
44.8 MB
총 파라미터: 11,177,538 개
연산량 (MACs): 8.37 GMACs per sample
연산량 (FLOPs): 16.75 GFLOPs per sample
샘플 당 평균 Forward Pass 시간: 0.84ms (100회 반복)
샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 219.19 MB


efficientnet_b0 (49차)
총 파라미터: 4,010,110 개
연산량 (MACs): 1.90 GMACs per sample
연산량 (FLOPs): 3.80 GFLOPs per sample
샘플 당 평균 Forward Pass 시간: 1.55ms (100회 반복)
샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 126.40 MB


mobilenet_v4 (50차)
총 파라미터: 2,495,586 개
연산량 (MACs): 0.84 GMACs per sample
연산량 (FLOPs): 1.69 GFLOPs per sample
샘플 당 평균 Forward Pass 시간: 1.05ms (100회 반복)
샘플 당 Forward Pass 시 최대 GPU 메모리 사용량: 72.07 MB






43모델로 지금 224 (56*4) 버전을 테스트 중이다.
이거의 성능이 xie 2019 (91.08)을 넘으면, 224 (56*4) 버전의 데이터 로더로 베이스라인들을 다시 학습시켜봐야 한ㅁ.
그리고 xie2019도 inference.py에서 171줄의 변수값을 224로 재설정 필요.


성능은 말고, 속도 지표만으로 480 vs 224 비교표도 만들 수 있을 듯.

480 버전의 표는 xie2019 (91.08)... 로 비교하는 것도 좀 애매한 건가?




* Forward Pass 계산 시, Our Model은 패칭 방식 때문에 배치 크기가 증가하긴 하지만, 교수님 말씀처럼 어차피 병렬처리되므로 배제할 이슈라고 판단했습니다.
(실제로 패치 개수를 기존의 16개 대신에 1개로 변경해본 결과, Forward Pass 시간 변화는 미미했습니다.)


* xie 모델과 Our Model의 인풋 리사이즈가 달랐습니다.
Sewer-ML 논문의 xie2019 (F1_normal: 91.08)인 인풋은 (3,224,224)
Our Model의 (F1_normal: 92.08)은 인풋은 (3,480,480)

그래서 Sewer-ML 논문의 인풋 사이즈를 Our Model 사이즈로 리사이즈하자, Sewer-ML의 Forward Pass 시간이 크게 증가했습니다.
이 방식을 사용하면 Our Model의 Forward Pass 시간이 xie보다 낮아집니다.
하지만 이 방식을 채택하면 아래의 문제가 있습니다.
Forward Pass 시간 비교 때는 인풋 사이즈가 같은 환경이고, F1_normal 비교 때는 인풋 사이즈가 다릅니다.
따라서 지표 선택에 유리하도록 환경을 바꾸는 것이라서 문제가 있다고 판단했습니다.



51차: sewer-ml 224짜리 하이브리드
log/Sewer-TAPNEW/run_20251107_185824_51
2025-11-08 10:19:38,897 - INFO - 연산량 (MACs): 0.09 GMACs per sample
2025-11-08 10:19:38,897 - INFO - 연산량 (FLOPs): 0.18 GFLOPs per sample
2025-11-08 10:19:38,985 - INFO - 샘플 당 평균 Forward Pass 시간: 0.72ms (100회 반복)
2025-11-08 10:19:38,985 - INFO -   - Encoder: 0.36ms
2025-11-08 10:19:38,985 - INFO -   - Decoder: 0.33ms
2025-11-08 10:19:38,985 - INFO -   - Classifier: 0.03ms
2025-11-08 10:19:38,985 - INFO - 샘플 당 최대 GPU 메모리 사용량: 27.91 MB



52차: sewer-tap 224짜리 하이브리드
run_20251108_120255_52

53차: sewer-tapnew 224짜리 하이브리드
run_20251108_121006_53

앞으로 224짜리 하이브리드는 고정.

54차: resnet18, sewer-tap
run_resnet18_20251108_122247_54

55차: efficientnet_b0, sewer-tap
run_efficientnet_b0_20251108_122449_55

56차: mobilener_v4, sewer-tap
run_mobilenet_v4_20251108_122605_56

57차: resnet18, sewer-tapnew
run_resnet18_20251108_122924_57

58차: efficientnet_b0, sewer-tapnew
run_efficientnet_b0_20251108_123359_58

59차: mobilener_v4, sewer-tapnew
run_mobilenet_v4_20251108_123828_59

60차: resnet18, sewer-ml
run_resnet18_20251108_125319_60

61차: efficientnet_b0, sewer-ml
run_efficientnet_b0_20251108_135948_61

62차: mobilenet_v4, sewer-ml
run_mobilenet_v4_20251108_163343_62

63차: 51차를 재실험. 하이브리드모델, sewer-ml
log/Sewer-ML/run_20251109_162437_63

defect value 0: 552820 (negative, label 0)
defect value 1: 487309 (positive, label 1)
positive/defect=1.134434209095256