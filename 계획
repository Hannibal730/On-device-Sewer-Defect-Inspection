1차 시도: 바닐라 efficientnet_b0_feat2 85.46
2차: 1차의 qam end 0.5 -> 0.0 (1차 대비 성능 향상. 이후 차시부터 qam=0.0 사용.) 86.23
3차: 2차의 n_heads 4->2 (2차 대비 성능향상. 이후 차시부터 n_heads =2 사용.) 86.38
4차: 3차의 positional_encoding 끄기 (3차 대비 성능 하락. 이후 차시부터 positional encoding true 고정) 85.54
5차: 3차에 스케줄프리 도입 (성능 소폭 상승.) 86.62
6차: 5차의 AdamW 스케줄프리 -> SGD 스케줄프리(모멘텀0.9) 70퍼대 
7차: 5차의 efficientnet_b0_feat2 -> mobilenet_v3_small_feat1 80.23
8차: 5차의 efficientnet_b0_feat2 -> resnet18_layer1 84.92
9차: 5차의 데이터 수를 늘리고 에포크도 늘리기. 0.01 -> 0.1, 30 ->50 (9차는 30에포크 이전에 이미 5차보다 성능이 좋았음. 따라서 데이터 개수가 늘수록 성능 향상됨.) 87.18
10차: 5차의 데이터 수를 0.01 -> 0.3, 배치사이즈 8 -> 16.   87.63 (과적합 너무너무 심함. 거의 10에포크 이후로는 최고성능 갱신이 어려워지고 진동도 심함.)

11차:
0.3 -> 0.1 데이터 비율.    202850    85.89
배치 사이즈 16 -> 32
classifier단에 중간층 최초 삽입
디코더 쿼리 패치 개수 계산식을 레이블 개수와 동일시하여 각 쿼리패치가 각 레이블 특징을 학습하도록 유도 (패치 개수 1-> 2)
qam을 기존에는 패치 순서마다 고정된 선형값을 적용(아마 시계열인 것과 영향..?)이었지만, 각 패치마다 지정범위의 유니폼 분포에서 랜덤값을 마스킹 확률로 사용.
qam 0.1~0.4 
학습 결과 epoch당 val acc를 확인해보니까 들쭉날쭉 학습 안정성이 낮아졌다.

12차: 11차에서 qam 0.1~0.4 -> qam 0.0~0.0 으로 수정함.  212056   86.71
실험결과, epoch당 val acc를 확인해보니까 12차가 11차보다 학습 안정성이 높다.
따라서 qam이 효과가 없다고 판단하여 qam 사용 안 하기로 함.

13차: 12차의 데이터 비율 0.1 -> 0.3   87.86
(10차와 다른 점은 배치 사이즈 16 -> 32, 분류단에 중간층 삽입.)
성능 나쁘지 않음.

14차: 13차의 qam 0.0 -> 0.1 추가 87.75
qam 고정 비율로 사용 (일반화 성능 도모)
그 결과 성능은 qam 0.0인 13차와 비슷해보였지만 val acc 그래프를 보니 학습 불안정성이 너무 커졌다.
따라서 앞으로 qam 은 0.0으로 고정해둬야겠다.

15차: 13차에서 in_channels, 트랜스폼 수정.  021944 
지금까지의 in_channnels 코드는 변수값이 3일 때에 내 의도처럼 입력 이미지의 rgb 채널을 그대로 사용하는 게 아니라, 그레이스케일을 3개 채널로 복사하고 사용하는 방식이었다...
in_channels가 3일 때, 내 의도대로 입력 이미지의 rgb채널을 그대로 cnn에 입력하도록 수정했다.
그리고 in_channels가 3일 때에 기존에는 흑백 정규화가 사용되던 오류를 sewer-ml 공식 레포의 트랜스폼을 사용 (i_channels = 1일 때는 커스텀 트랜스폼)하도록 수정했다. (어그멘테이션 -> to텐서 -> 정규화 순서 )

16차: 15차에서 데이터를 0.3에서 1.0 으로 수정.


17차: run_no_cats로 15차에서 CatsDecoder만 제외하고, 인코더랑 분류단만 연결하여 실험 진행

---- 10.23 랩미팅-----
피드백: 디코더 패치 개수를 1개로.
---------------------

18차: 16차에서 디코더 패치 개수만 1로. 물론 num_labels는 여전히 2로써 분리시킴.
성능이 비슷함..

19차: 18차에서
러너블 쿼리를 임베딩시키고(시드쿼리) 인코더 출력시퀀스와 어텐션하여 어텐션 벨류 만들고, 그걸 디코더블럭의 쿼리로 사용
스케줄프리 끄고, 코사인 스케줄러 도입
데이터 비율 1.0에서 0.1로

20차: 18차에서
스케줄프리 끄고, 코사인 스케줄러 도입
데이터 비율 1.0에서 0.1로
(깃에서 서버로 파일 복붙)

19차는 attn_pooling이 true인 셈, 20차는 false인 셈으로 옵션 세팅해둠.




멀티헤드도 늘려봐야겠다.

테스트셋 총 추론시간과 평균 추론시간을 계산할 때  순수하게 inference되는 시간만 측정하지 않고, 데이터로더 과정까지 포함한 시간을 측정하는 중이라서 수정 필요. 로컬에는 수정이 반영된 상태.












멀티 헤드 개수 늘리기 (다양한 종류의 피처를 학습 가능. emb_dim은 고정한 채로 멀티 헤드 개수만 늘리면 각 헤드가 충분한 정보를 못 담고 성능하락 가능. 헤드 개수 느는 건 파라미터랑 영향 없음.)
디코더 레이어 늘리기 (피처를 점진적 추상화 도모. res_attention으로 과적합 및 기울기 소실 예방 가능)