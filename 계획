1차 시도: 바닐라 efficientnet_b0_feat2 85.46
2차: 1차의 qam end 0.5 -> 0.0 (1차 대비 성능 향상. 이후 차시부터 qam=0.0 사용.) 86.23
3차: 2차의 n_heads 4->2 (2차 대비 성능향상. 이후 차시부터 n_heads =2 사용.) 86.38
4차: 3차의 positional_encoding 끄기 (3차 대비 성능 하락. 이후 차시부터 positional encoding true 고정) 85.54
5차: 3차에 스케줄프리 도입 (성능 소폭 상승.) 86.62
6차: 5차의 AdamW 스케줄프리 -> SGD 스케줄프리(모멘텀0.9) 70퍼대 
7차: 5차의 efficientnet_b0_feat2 -> mobilenet_v3_small_feat1 80.23
8차: 5차의 efficientnet_b0_feat2 -> resnet18_layer1 84.92
9차: 5차의 데이터 수를 늘리고 에포크도 늘리기. 0.01 -> 0.1, 30 ->50 (9차는 30에포크 이전에 이미 5차보다 성능이 좋았음. 따라서 데이터 개수가 늘수록 성능 향상됨.) 87.18
10차: 5차의 데이터 수를 0.01 -> 0.3, 배치사이즈 8 -> 16.   87.63 (과적합 너무너무 심함. 거의 10에포크 이후로는 최고성능 갱신이 어려워지고 진동도 심함.)

11차:
0.3 -> 0.1 데이터 비율.    202850    85.89
배치 사이즈 16 -> 32
classifier단에 중간층 최초 삽입
디코더 쿼리 패치 개수 계산식을 레이블 개수와 동일시하여 각 쿼리패치가 각 레이블 특징을 학습하도록 유도 (패치 개수 1-> 2)
qam을 기존에는 패치 순서마다 고정된 선형값을 적용(아마 시계열인 것과 영향..?)이었지만, 각 패치마다 지정범위의 유니폼 분포에서 랜덤값을 마스킹 확률로 사용.
qam 0.1~0.4 
학습 결과 epoch당 val acc를 확인해보니까 들쭉날쭉 학습 안정성이 낮아졌다.

12차: 11차에서 qam 0.1~0.4 -> qam 0.0~0.0 으로 수정함.  212056   86.71
실험결과, epoch당 val acc를 확인해보니까 12차가 11차보다 학습 안정성이 높다.
따라서 qam이 효과가 없다고 판단하여 qam 사용 안 하기로 함.

13차: 12차의 데이터 비율 0.1 -> 0.3   87.86
(10차와 다른 점은 배치 사이즈 16 -> 32, 분류단에 중간층 삽입.)
성능 나쁘지 않음.

14차: 13차의 qam 0.0 -> 0.1 추가 87.75
qam 고정 비율로 사용 (일반화 성능 도모)
그 결과 성능은 qam 0.0인 13차와 비슷해보였지만 val acc 그래프를 보니 학습 불안정성이 너무 커졌다.
따라서 앞으로 qam 은 0.0으로 고정해둬야겠다.

15차: 13차에서 in_channels, 트랜스폼 수정.  021944 
지금까지의 in_channnels 코드는 변수값이 3일 때에 내 의도처럼 입력 이미지의 rgb 채널을 그대로 사용하는 게 아니라, 그레이스케일을 3개 채널로 복사하고 사용하는 방식이었다...
in_channels가 3일 때, 내 의도대로 입력 이미지의 rgb채널을 그대로 cnn에 입력하도록 수정했다.
그리고 in_channels가 3일 때에 기존에는 흑백 정규화가 사용되던 오류를 sewer-ml 공식 레포의 트랜스폼을 사용 (i_channels = 1일 때는 커스텀 트랜스폼)하도록 수정했다. (어그멘테이션 -> to텐서 -> 정규화 순서 )

16차: 15차에서 데이터를 0.3에서 1.0 으로 수정.


17차: run_no_cats로 15차에서 CatsDecoder만 제외하고, 인코더랑 분류단만 연결하여 실험 진행

---- 10.23 랩미팅-----
피드백: 디코더 패치 개수를 1개로.
---------------------

18차: 16차에서 디코더 패치 개수만 1로. 물론 num_labels는 여전히 2로써 분리시킴.
성능이 비슷함..

19차 89.69 : 18차에서  
attn_pooling 추가: 러너블 쿼리를 임베딩시키고(시드쿼리) 인코더 출력시퀀스와 어텐션하여 어텐션 벨류 만들고, 그걸 디코더블럭의 쿼리로 사용
스케줄프리 끄고, 코사인 스케줄러 도입
데이터 비율 1.0에서 0.1로

20차 89.08 : 19차에서 attn_pooling 제거 89.18

21차: 19차에서
self.learnable_queries = nn.Parameter(0.5*torch.randn(num_decoder_patches, featured_patch_dim))
-> 
self.learnable_queries = nn.Parameter(torch.empty(num_decoder_patches, featured_patch_dim))
별차이 없음.
Train Acc: 89.01%
Val Acc: 89.17% 
F1: 0.8917
2025-10-24 21:48:41,678 - INFO - 모델 파라미터 수:
2025-10-24 21:48:41,678 - INFO -   - Encoder (PatchConvEncoder):   19,138 개
2025-10-24 21:48:41,678 - INFO -     - conv_front (CNN Backbone):  19,090 개
2025-10-24 21:48:41,678 - INFO -     - 1x1_conv (Channel Proj):    0 개
2025-10-24 21:48:41,678 - INFO -     - norm (LayerNorm):           48 개
2025-10-24 21:48:41,678 - INFO -   - Decoder (CatsDecoder):        10,200 개
2025-10-24 21:48:41,678 - INFO -     - Embedding Layer (W_feat2emb):    600 개
2025-10-24 21:48:41,678 - INFO -     - Learnable Queries:               24 개
2025-10-24 21:48:41,678 - INFO -     - Positional Encoding (PE):        384 개
2025-10-24 21:48:41,678 - INFO -     - Decoder Layers (Cross-Attention): 8,592 개
2025-10-24 21:48:41,678 - INFO -     - Projection4Classifier:      600 개
2025-10-24 21:48:41,678 - INFO -   - Classifier (Projection MLP):  353 개
2025-10-24 21:48:41,678 - INFO -   - 총 파라미터:                  29,691 개


; 22차: 21차에서
; patch_size 120 -> 80 (Positional Encoding만 바뀜: 384-> 864)
; 별차이 없음.

; 23차: 21차에서
; emb_dim 24 -> 48 (임베딩 차원): 모델의 기본 체급. 늘리면 표현력이 크게 증가합니다.
; num_decoder_layers 2-> 4 (레이어 수): 모델의 깊이. 더 깊게 쌓으면 더 복잡한 관계를 학습할 수 있습니다.
; num_heads 2-> 4 (어텐션 헤드 수): 다양한 관점에서 특징을 볼 수 있는 능력.
; decoder_ff_ratio 2-> 4 (FFN 비율): FFN의 복잡도를 높여 표현력을 보강합니다
; 2025-10-24 23:48:22,303 - INFO - 모델 파라미터 수:
; 2025-10-24 23:48:22,318 - INFO -   - Encoder (PatchConvEncoder):   19,138 개
; 2025-10-24 23:48:22,318 - INFO -     - conv_front (CNN Backbone):  19,090 개
; 2025-10-24 23:48:22,318 - INFO -     - 1x1_conv (Channel Proj):    0 개
; 2025-10-24 23:48:22,318 - INFO -     - norm (LayerNorm):           48 개
; 2025-10-24 23:48:22,318 - INFO -   - Decoder (CatsDecoder):        97,824 개
; 2025-10-24 23:48:22,318 - INFO -     - Embedding Layer (W_feat2emb):    1,200 개   emb_dim이 2배 증가해서.
; 2025-10-24 23:48:22,318 - INFO -     - Learnable Queries:               24 개
; 2025-10-24 23:48:22,318 - INFO -     - Positional Encoding (PE):        768 개     emb_dim이 2배 증가해서.
; 2025-10-24 23:48:22,318 - INFO -     - Decoder Layers (Cross-Attention): 94,656 개
; 2025-10-24 23:48:22,319 - INFO -     - Projection4Classifier:      1,176 개        emb_dim이 2배 증가해서.
; 2025-10-24 23:48:22,319 - INFO -   - Classifier (Projection MLP):  353 개
; 2025-10-24 23:48:22,319 - INFO -   - 총 파라미터:                  117,315 개
; 별차이 없음.


; --- 작전 변경 ---
; 목표:
;     데이터 비율을 0.01로 고정하고, train acc를 100%에 가깝도록 과적합부터 시켜보기.
; 지금까지의 문제점:
;     에포크가 진행될 때마다 loss가 감소하긴 하지만, train acc와 val acc가 89%대에서 계속 정체함.
;     train acc가 100%에 수렴하지 않는 지금의 현상은 모델 자체의 성능이 부족하다고 판단함.
;     일단은 과적합을 시켜놓고서 추후에 일반화를 도모하기로 방향성 변경.
; 방법:
;     cnn 백본들을 바꿔보면서 train acc가 90% 이상인 모델들을 찾기. 다시 말해, 피지컬이 받쳐주는 백본 찾기.
; 밑 실험들은 데이터 비율 0.01
; ----------------

; 24차: 21차에서 efficientnet_b0_feat2 -> efficientnet_b0_feat3
; Train Acc: 92.30%
; Test Acc: 88.23%
; F1 Score for 'Normal': 0.8909
; 2025-10-25 01:33:26,370 - INFO - 모델 파라미터 수:
; 2025-10-25 01:33:26,370 - INFO -   - Encoder (PatchConvEncoder):   66,762 개
; 2025-10-25 01:33:26,370 - INFO -     - conv_front (CNN Backbone):  65,730 개
; 2025-10-25 01:33:26,370 - INFO -     - 1x1_conv (Channel Proj):    984 개
; 2025-10-25 01:33:26,370 - INFO -     - norm (LayerNorm):           48 개
; 2025-10-25 01:33:26,370 - INFO -   - Decoder (CatsDecoder):        10,200 개
; 2025-10-25 01:33:26,370 - INFO -     - Embedding Layer (W_feat2emb):    600 개
; 2025-10-25 01:33:26,370 - INFO -     - Learnable Queries:               24 개
; 2025-10-25 01:33:26,370 - INFO -     - Positional Encoding (PE):        384 개
; 2025-10-25 01:33:26,370 - INFO -     - Decoder Layers (Cross-Attention): 8,592 개
; 2025-10-25 01:33:26,370 - INFO -     - Projection4Classifier:      600 개
; 2025-10-25 01:33:26,370 - INFO -   - Classifier (Projection MLP):  353 개
; 2025-10-25 01:33:26,370 - INFO -   - 총 파라미터:                  77,315 개

; 25차: 24차에서 dropout 0.1 -> 0.0
; Train Acc: 93.54%
; Test Acc: 87.77%
; F1 Score for 'Normal': 0.8870
; 따라서 efficientnet_b0_feat3는 모델 피지컬은 충분하다고 판단.
; dropout 옵션 유무가 영향력 있다고 판단.

; 26차: 21차에서 efficientnet_b0_feat2 -> mobilenet_v3_small_feat1
; Train Acc: 82.46%
; Val Acc: 81.92%
; 너무 낮음.
; 2025-10-25 02:10:59,931 - INFO - 모델 파라미터 수:
; 2025-10-25 02:10:59,931 - INFO -   - Encoder (PatchConvEncoder):   1,664 개
; 2025-10-25 02:10:59,931 - INFO -     - conv_front (CNN Backbone):  1,208 개
; 2025-10-25 02:10:59,931 - INFO -     - 1x1_conv (Channel Proj):    408 개
; 2025-10-25 02:10:59,931 - INFO -     - norm (LayerNorm):           48 개
; 2025-10-25 02:10:59,931 - INFO -   - Decoder (CatsDecoder):        10,200 개
; 2025-10-25 02:10:59,931 - INFO -     - Embedding Layer (W_feat2emb):    600 개
; 2025-10-25 02:10:59,931 - INFO -     - Learnable Queries:               24 개
; 2025-10-25 02:10:59,931 - INFO -     - Positional Encoding (PE):        384 개
; 2025-10-25 02:10:59,931 - INFO -     - Decoder Layers (Cross-Attention): 8,592 개
; 2025-10-25 02:10:59,931 - INFO -     - Projection4Classifier:      600 개
; 2025-10-25 02:10:59,931 - INFO -   - Classifier (Projection MLP):  353 개
; 2025-10-25 02:10:59,931 - INFO -   - 총 파라미터:                  12,217 개


; 27차: 21차에서 efficientnet_b0_feat2 -> mobilenet_v3_small_feat3
; Train Acc: 89.46%
; Test Acc: 86.23%
; F1 Score for 'Normal': 0.8698
; 2025-10-25 02:21:55,863 - INFO - 모델 파라미터 수:
; 2025-10-25 02:21:55,863 - INFO -   - Encoder (PatchConvEncoder):   10,536 개
; 2025-10-25 02:21:55,863 - INFO -     - conv_front (CNN Backbone):  10,488 개
; 2025-10-25 02:21:55,863 - INFO -     - 1x1_conv (Channel Proj):    0 개
; 2025-10-25 02:21:55,863 - INFO -     - norm (LayerNorm):           48 개
; 2025-10-25 02:21:55,863 - INFO -   - Decoder (CatsDecoder):        10,200 개
; 2025-10-25 02:21:55,863 - INFO -     - Embedding Layer (W_feat2emb):    600 개
; 2025-10-25 02:21:55,863 - INFO -     - Learnable Queries:               24 개
; 2025-10-25 02:21:55,863 - INFO -     - Positional Encoding (PE):        384 개
; 2025-10-25 02:21:55,863 - INFO -     - Decoder Layers (Cross-Attention): 8,592 개
; 2025-10-25 02:21:55,863 - INFO -     - Projection4Classifier:      600 개
; 2025-10-25 02:21:55,863 - INFO -   - Classifier (Projection MLP):  353 개
; 2025-10-25 02:21:55,863 - INFO -   - 총 파라미터:                  21,089 개


; 28차: 21차에서 efficientnet_b0_feat2 -> mobilenet_v3_small_feat4
; Train Acc: 89.72%
; Test Acc: 87.00%
; F1 Score for 'Normal': 0.8807
; 2025-10-25 02:50:53,310 - INFO - 모델 파라미터 수:
; 2025-10-25 02:50:53,310 - INFO -   - Encoder (PatchConvEncoder):   25,256 개
; 2025-10-25 02:50:53,310 - INFO -     - conv_front (CNN Backbone):  24,224 개
; 2025-10-25 02:50:53,310 - INFO -     - 1x1_conv (Channel Proj):    984 개
; 2025-10-25 02:50:53,310 - INFO -     - norm (LayerNorm):           48 개
; 2025-10-25 02:50:53,310 - INFO -   - Decoder (CatsDecoder):        10,200 개
; 2025-10-25 02:50:53,310 - INFO -     - Embedding Layer (W_feat2emb):    600 개
; 2025-10-25 02:50:53,310 - INFO -     - Learnable Queries:               24 개
; 2025-10-25 02:50:53,310 - INFO -     - Positional Encoding (PE):        384 개
; 2025-10-25 02:50:53,310 - INFO -     - Decoder Layers (Cross-Attention): 8,592 개
; 2025-10-25 02:50:53,310 - INFO -     - Projection4Classifier:      600 개
; 2025-10-25 02:50:53,310 - INFO -   - Classifier (Projection MLP):  353 개
; 2025-10-25 02:50:53,310 - INFO -   - 총 파라미터:                  35,809 개

; 29차: 21차에서 efficientnet_b0_feat2 -> mobilenet_v3_small_feat5
; 2025-10-25 03:43:30,294 - INFO - 모델 파라미터 수:
; 2025-10-25 03:43:30,294 - INFO -   - Encoder (PatchConvEncoder):   82,520 개
; 2025-10-25 03:43:30,294 - INFO -     - conv_front (CNN Backbone):  81,488 개
; 2025-10-25 03:43:30,294 - INFO -     - 1x1_conv (Channel Proj):    984 개
; 2025-10-25 03:43:30,309 - INFO -     - norm (LayerNorm):           48 개
; 2025-10-25 03:43:30,309 - INFO -   - Decoder (CatsDecoder):        10,200 개
; 2025-10-25 03:43:30,309 - INFO -     - Embedding Layer (W_feat2emb):    600 개
; 2025-10-25 03:43:30,309 - INFO -     - Learnable Queries:               24 개
; 2025-10-25 03:43:30,309 - INFO -     - Positional Encoding (PE):        384 개
; 2025-10-25 03:43:30,309 - INFO -     - Decoder Layers (Cross-Attention): 8,592 개
; 2025-10-25 03:43:30,309 - INFO -     - Projection4Classifier:      600 개
; 2025-10-25 03:43:30,309 - INFO -   - Classifier (Projection MLP):  353 개
; 2025-10-25 03:43:30,309 - INFO -   - 총 파라미터:                  93,073 개
; 9만개면, 이피션트넷 앞단에 리니어만 연결한 모델의 파라미터수랑 비슷한데, 그러면 경량화 의미가 없다. 따라서 진행 안 함.


30차: 21차의 드롭아웃 0.1 -> 0.0, 데이터비율 0.1 -> 0.01
Train Acc: 89.01%
Test Acc: 87.62%
F1 Score for 'Normal': 0.8836
; 아래는 21차 꺼
; Train Acc: 89.01%
; Val Acc: 89.17% 
; F1: 0.8917
드롭아웃 0.0이 0.1보다 안 좋은 것 같다.


; 31차: 25차에서 efficientnet_b0_feat3 -> mobilenet_v3_small_feat4 30에포크
; Train Acc: 90.70%
; Test Acc: 87.46%
; F1 Score for 'Normal': 0.8838
; 2025-10-25 11:55:37,666 - INFO - 모델 파라미터 수:
; 2025-10-25 11:55:37,666 - INFO -   - Encoder (PatchConvEncoder):   25,256 개
; 2025-10-25 11:55:37,666 - INFO -     - conv_front (CNN Backbone):  24,224 개
; 2025-10-25 11:55:37,666 - INFO -     - 1x1_conv (Channel Proj):    984 개
; 2025-10-25 11:55:37,666 - INFO -     - norm (LayerNorm):           48 개
; 2025-10-25 11:55:37,666 - INFO -   - Decoder (CatsDecoder):        10,200 개
; 2025-10-25 11:55:37,666 - INFO -     - Embedding Layer (W_feat2emb):    600 개
; 2025-10-25 11:55:37,666 - INFO -     - Learnable Queries:               24 개
; 2025-10-25 11:55:37,666 - INFO -     - Positional Encoding (PE):        384 개
; 2025-10-25 11:55:37,666 - INFO -     - Decoder Layers (Cross-Attention): 8,592 개
; 2025-10-25 11:55:37,666 - INFO -     - Projection4Classifier:      600 개
; 2025-10-25 11:55:37,666 - INFO -   - Classifier (Projection MLP):  353 개
; 2025-10-25 11:55:37,666 - INFO -   - 총 파라미터:                  35,809 개


; 32차: 30차의 CnnFeatureExtractor forward 마지막에 SEBlock 추가.
; train acc가 89를 넘겨야 의미있는 시도가 된다.
; Train Acc: 88.78%
; Test Acc: 87.31%
; F1 Score for 'Normal': 0.8805
; 따라서 seblock 추가는 폐기


; 33차: 30차에 cutmix, fpn 추가
; Train Acc: 84.88%
; Test Acc: 87.46%
; F1 Score for 'Normal': 0.8863
; cutmix와 fpn을 적용하니까 train acc보다 val acc가 훨씬 높은 현상이 발생함.
; CutMix가 훈련 시에만 적용되고, 검증 시에는 적용되지 않기 때문으로 추측.
; fpn은 저수준 특징 (Low-level): features[:2], 고수준 특징 (High-level): features[2:3]을 기존처럼 구하고, 두 특징의 해상도와 채널 수를 맞춘 뒤, 이를 더합니다 (feat1_upsampled + feat2). 덕분에 더 다채롭게 특징을 뽑아서 성능개선에 영향 줄 듯.


; 34차: 33차의 에포크를 30 -> 60
; 만약 33차보다 성능이 좋다면, 에포크 이슈일 수 있으니까 30차꺼를 에포크 30 -> 60으로 해보자.
; Train Acc: 85.87%
; Test Acc: 88.31%
; F1 Score for 'Normal': 0.8925


35차: 30차의 에포크를 60으로 수정
Train Acc: 91.77%
Test Acc: 88.08%
F1 Score for 'Normal': 0.8892
; 아래는 30차
; Train Acc: 89.01%
; Test Acc: 87.62%
; F1 Score for 'Normal': 0.8836
이거이거 에포크나 스케줄러가 너무 중요해보인다....
일단 에포크는 30보다 커야 하는 게 맞다.


36차: 30차의 CosineAnnealingLR를
CosineAnnealingWarmRestarts (T_0=10, T_mult=2, 에포크 70 (10 에포크부터, 2배의 에포크기간동안 코사인 주기.)) 으로 수정.
F1 average 기준 베스트 모델 저장에서 F1 Normal 기준으로 변경
Train Acc: 92.42%
Test Acc: 87.38%
F1 Score for 'Normal': 0.8815
35차랑 36차의 차이점이 스케줄러랑 베스트 모델 저장 기준이다.
근데 스케줄러는 35차의 CosineAnnealingLR이 Test Acc랑 F1 normal이 더 높다.


37차는 36차에 드롭아웃 0.1 추가.
아마 낮게 나올 듯.
만약 낮게 나온다면 CosineAnnealingWarmRestarts를 안 쓰고, 다시 CosineAnnealingLR를 쓰는 35차로 돌아가자.




38차: 35차의 F1 average 기준 베스트 모델 저장에서 F1 Normal 기준으로 변경




39차는 38차에 드롭아웃 0.1 추가






샘플 원본 사이즈에 따라 img_size랑 patch_size 동적 변환...  패치 개수만 동일하게끔!!










21차 (레이어 1개당 4,296개 x 2개 레이어)
emb_dim=24, num_heads=2, decoder_ff_ratio=2
Cross-Attention: (24 * 24 * 3) + (24 * 24) (Q,K,V + Output Proj) ≈ 2,304개
FFN: (24 * 48) + (24 * 24) (Linear1 + Linear2) ≈ 1,728개
LayerNorm: 24*2 + 24*2 (두 개의 LayerNorm) = 96개
레이어 1개당 약 4,296개 -> 4,296 * 2개 레이어 = 8,592개

23차 (레이어 1개당 23,664개 x 4개 레이어)
emb_dim=48, num_heads=4, decoder_ff_ratio=4
Cross-Attention: (48 * 48 * 3) + (48 * 48) ≈ 9,216개
FFN: (48 * 192) + (96 * 48) ≈ 13,824개
LayerNorm: 48*2 + 48*2 = 192개
레이어 1개당 약 23,664개 -> 23,664 * 4개 레이어 = 94,656개
