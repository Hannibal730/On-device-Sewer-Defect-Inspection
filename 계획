1차 시도: 바닐라 efficientnet_b0_feat2 85.46
2차: 1차의 qam end 0.5 -> 0.0 (1차 대비 성능 향상. 이후 차시부터 qam=0.0 사용.) 86.23
3차: 2차의 n_heads 4->2 (2차 대비 성능향상. 이후 차시부터 n_heads =2 사용.) 86.38
4차: 3차의 positional_encoding 끄기 (3차 대비 성능 하락. 이후 차시부터 positional encoding true 고정) 85.54
5차: 3차에 스케줄프리 도입 (성능 소폭 상승.) 86.62
6차: 5차의 AdamW 스케줄프리 -> SGD 스케줄프리(모멘텀0.9) 70퍼대 . 30에퐄까지 안 돌려서 기록 없음.
7차: 5차의 efficientnet_b0_feat2 -> mobilenet_v3_small_feat1 80.23
8차: 5차의 efficientnet_b0_feat2 -> resnet18_layer1 84.92



9차: 5차의 데이터 수를 늘리고 에포크도 늘리기. 0.01 -> 0.1, 30 ->50 (9차는 30에포크 이전에 이미 5차보다 성능이 좋았음. 따라서 데이터 개수가 늘수록 성능 향상됨.) 87.18


0.3, 배치사이즈 8에사16





mobilenet_v3_small_feat1 (채널3)
2025-10-19 22:45:34,660 - INFO -   - Encoder (PatchConvEncoder): 1,664 개
2025-10-19 22:45:34,660 - INFO -   - Decoder (CatsDecoder):      10,200 개
2025-10-19 22:45:34,660 - INFO -   - Classifier (Linear Head):   50 개
2025-10-19 22:45:34,660 - INFO -   - 총 파라미터:                  11,914 개





efficientnet_b0_feat2 (채널3)
2025-10-19 04:50:15,348 - INFO -   - Encoder (PatchConvEncoder): 19,138 개
2025-10-19 04:50:15,348 - INFO -   - Decoder (CatsDecoder):      10,200 개
2025-10-19 04:50:15,348 - INFO -   - Classifier (Linear Head):   50 개
2025-10-19 04:50:15,348 - INFO -   - 총 파라미터:                  29,388 개


resnet18_layer1 (3채널)
2025-10-19 23:36:13,126 - INFO -   - Encoder (PatchConvEncoder): 159,112 개
2025-10-19 23:36:13,126 - INFO -   - Decoder (CatsDecoder):      10,200 개
2025-10-19 23:36:13,128 - INFO -   - Classifier (Linear Head):   50 개
2025-10-19 23:36:13,128 - INFO -   - 총 파라미터:                  169,362 개



의 in_channels 3 -> 1



진짜 마지막 실험 때는 피처추출단에 바로 분류단을 연결시켜서 성능을 확인해봐야겠다. 이게 내 꺼보다 성능이 낮아야만 해.

